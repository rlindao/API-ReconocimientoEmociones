{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FlaskApiEmociones.ipynb","provenance":[],"mount_file_id":"18v-pCtQgNjU9jthZWRnuuSNplfj39tjh","authorship_tag":"ABX9TyMEksf9dUJyidJ1Yc2kHmi5"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ltb_H0-VXs5r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":292},"executionInfo":{"status":"ok","timestamp":1599494455702,"user_tz":300,"elapsed":4346,"user":{"displayName":"chatbot videojuego","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmGBFSZl9e2oDPe-pzdF2u6Ir_Tz-jZ5g7xLT9=s64","userId":"15267890011900068505"}},"outputId":"539d3a65-eee8-4553-9874-26ca6792a996"},"source":["!pip install flask-ngrok"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting flask-ngrok\n","  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.10)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DoluLAf5YT4p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"ok","timestamp":1599494458541,"user_tz":300,"elapsed":7172,"user":{"displayName":"chatbot videojuego","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmGBFSZl9e2oDPe-pzdF2u6Ir_Tz-jZ5g7xLT9=s64","userId":"15267890011900068505"}},"outputId":"c8d8aa29-26a2-462f-bd5e-6901ef021da3"},"source":["!pip install -U jsonpickle"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting jsonpickle\n","  Downloading https://files.pythonhosted.org/packages/af/ca/4fee219cc4113a5635e348ad951cf8a2e47fed2e3342312493f5b73d0007/jsonpickle-1.4.1-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle) (1.7.0)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle) (3.1.0)\n","Installing collected packages: jsonpickle\n","Successfully installed jsonpickle-1.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nDsxE_QkXb8x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"4efff826-e0ca-4e48-afc7-8e14c3695e61"},"source":["from flask import Flask, request, Response\n","from flask_ngrok import run_with_ngrok\n","import jsonpickle\n","import numpy as np\n","import cv2\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import datetime\n","\n","\n","\n","# Initialize the Flask application\n","app = Flask(__name__)\n","run_with_ngrok(app) \n","\n","FACE_DETECTOR_PATH = '/content/drive/My Drive/Reconocimiento De Emociones/src/haarcascade_frontalface_default.xml'\n","RUTA_DE_DATA_GUARDADA = 'content/drive/My Drive/Reconocimiento De Emociones/data/'\n","# Create the model\n","model = Sequential()\n","\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(1024, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(7, activation='softmax'))\n","\n","# route http posts to this method\n","@app.route('/api/test', methods=['POST'])\n","def test():\n","    r = request\n","    # convert string of image data to uint8\n","    nparr = np.fromstring(r.data, np.uint8)\n","    # decode image\n","    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n","    # do some fancy processing here....\n","    # build a response dict to send back to client\n","    response = {'message': 'image received. size={}x{}'.format(img.shape[1],\n","                                                               img.shape[0])}\n","    # encode response using jsonpickle\n","    response_pickled = jsonpickle.encode(response)\n","\n","    return Response(response=response_pickled, status=200, \n","                    mimetype=\"application/json\")\n","    \n","@app.route(\"/predecir\", methods=[\"POST\"])\n","def predecir():\n","    r = request\n","    # convert string of image data to uint8\n","    nparr = np.fromstring(r.data, np.uint8)\n","    # decode image\n","    image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    detector = cv2.CascadeClassifier('/content/drive/My Drive/Reconocimiento De Emociones/src/haarcascade_frontalface_default.xml')\n","    rects = detector.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5,minSize=(30, 30),\n","                                      flags = cv2.CASCADE_SCALE_IMAGE)\n","    # construct a list of bounding boxes from the detection\n","    rects = [(int(x), int(y), int(x + w), int(y + h)) for (x, y, w, h) in rects]\n","\t\t# update the data dictionary with the faces detected\n","    response = {\"num_faces\": len(rects), \"faces\": rects, \"success\": True }\n","    response_pickled = jsonpickle.encode(response)\n","    return Response(response=response_pickled, status=200, \n","                    mimetype=\"application/json\")\n","\n","@app.route(\"/emociones\", methods=[\"POST\"])\n","def detectarEmociones():\n","    model.load_weights('/content/drive/My Drive/Reconocimiento De Emociones/src/model.h5')\n","\n","    # prevents openCL usage and unnecessary logging messages\n","    cv2.ocl.setUseOpenCL(False)\n","\n","    # Diccionario de emociones\n","    emotion_dict = {0: \"Enojado\", 1: \"Disgustado\", 2: \"Temerosa\", 3: \"Feliz\", 4: \"Neutral\", 5: \"Triste\", 6: \"Sorprendido\"}\n","    #Hora actual\n","    hora_actual = datetime.datetime.now()\n","    # start the webcam feed\n","    #cap = cv2.VideoCapture(0)\n","    r = request\n","    # convert string of image data to uint8\n","    nparr = np.fromstring(r.data, np.uint8)\n","    # decode image\n","    image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n","    #codigo de guardado\n","    #imagennueva = cv2.imread(image)\n","    #Guardamos la imagen\n","    #cv2.imwrite('kokonete.jpg',image)\n","    fecha= \"%s%s%s%s%s%srostrosindetectar.jpg\" % ( hora_actual.year ,\n","                                                   hora_actual.month ,\n","                                                   hora_actual.day , \n","                                                   hora_actual.hour ,\n","                                                   hora_actual.minute ,\n","                                                   hora_actual.second)\n","    RUTA_FINAL = '/content/drive/My Drive/Reconocimiento De Emociones/data/' + fecha\n","    cv2.imwrite(RUTA_FINAL,image)\n","    #--fin de codigo de guardado\n","    facecasc = cv2.CascadeClassifier(FACE_DETECTOR_PATH)\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    faces = facecasc.detectMultiScale(gray,scaleFactor=1.3, minNeighbors=5)\n","    rects = facecasc.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5,\n","\t\t                      \tminSize=(30, 30), flags = cv2.CASCADE_SCALE_IMAGE)\n","    auxFrame = image.copy()\n","    for (x, y, w, h) in faces:\n","        rostro = auxFrame[y:y+h,x:x+w]\n","        rostro = cv2.resize(rostro,(150,150),interpolation= cv2.INTER_CUBIC)\n","        cv2.rectangle(image, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n","        roi_gray = gray[y:y + h, x:x + w]\n","        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n","        prediction = model.predict(cropped_img)\n","        maxindex = int(np.argmax(prediction))\n","        cv2.putText(image, emotion_dict[maxindex], (x+10, y-5), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n","        #codigo de guardado\n","        #imagennueva = cv2.imread(image)\n","        fecha= \"%s%s%s%s%s%srostrodetectado.jpg\" % ( hora_actual.year ,\n","                                                     hora_actual.month ,\n","                                                     hora_actual.day , \n","                                                     hora_actual.hour , \n","                                                     hora_actual.minute ,\n","                                                     hora_actual.second)\n","        RUTA_FINAL = '/content/drive/My Drive/Reconocimiento De Emociones/data/' + fecha\n","        cv2.imwrite(RUTA_FINAL,image)\n","        #--fin de codigo de guardado\n","    rects = [(int(x), int(y), int(x + w), int(y + h)) for (x, y, w, h) in rects]\n","    response = {\"num_faces\": len(faces), \"emocion\" :emotion_dict[maxindex] , \"faces\": rects, \"success\": True  , \"nombre_imagen\": fecha , \"URL_DRIVE\":RUTA_FINAL}\n","    response_pickled = jsonpickle.encode(response)\n","    return Response(response=response_pickled, status=200, \n","                mimetype=\"application/json\")\n","\n","def _grab_image(path=None, stream=None, url=None):\n","\t# if the path is not None, then load the image from disk\n","\tif path is not None:\n","\t\timage = cv2.imread(path)\n","\t# otherwise, the image does not reside on disk\n","\telse:\t\n","\t\t# if the URL is not None, then download the image\n","\t\tif url is not None:\n","\t\t\tresp = urllib.request.urlopen(url)\n","\t\t\tdata = resp.read()\n","\t\t# if the stream is not None, then the image has been uploaded\n","\t\telif stream is not None:\n","\t\t\tdata = stream.read()\n","\t\t# convert the image to a NumPy array and then read it into\n","\t\t# OpenCV format\n","\t\timage = np.asarray(bytearray(data), dtype=\"uint8\")\n","\t\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n","\t# return the image\n","\treturn image\n","\n","\n","\n","\n","# start flask app\n","app.run()"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"],"name":"stdout"},{"output_type":"stream","text":[" * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"],"name":"stderr"},{"output_type":"stream","text":[" * Running on http://f5fd960d93a7.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"],"name":"stdout"}]}]}